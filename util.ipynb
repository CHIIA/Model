{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "\n",
    "path_pdf= 'dataset/2014/pdf/'\n",
    "path_text = 'dataset/2014/txt/'\n",
    "\n",
    "for filename in os.listdir(path_pdf):\n",
    "    pdf = path_pdf + filename\n",
    "    txt = path_text + filename[:-4] + '.txt'\n",
    "    call([\"python\", \"pdfminer.six-master/tools/pdf2txt.py\", \"-o\", txt, pdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7322\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('dataset/2014/txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('dataset/2014/possible/')))\n",
    "print(len(os.listdir('dataset/2014/relevant/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treasury Wine Estates TPG.txt , No found\n",
      "littlelion1.txt , No found\n",
      "canning markets.txt , word = 1\n",
      "Paladin China nuclear.txt , word = 1\n",
      "R&F_Melbourne1.txt , word = 1\n",
      "puma.txt , word = 1\n",
      "241_Castlereagh1.txt , No found\n",
      "China merchants.txt , word = 1\n",
      "Chinese group swoops on rural deal _ Farm Online.txt , No found\n",
      "Gemtree1.txt , No found\n",
      "eliabethdowns1.txt , No found\n",
      "Australian_Dairy_Farms.txt , No found\n",
      "bega milk export.txt , word = 1\n",
      "kin mining unnamed chinese investor 3 million.txt , word = 1\n",
      "Lamboo1.txt , No found\n",
      "Baosteel__Aquila8.txt , No found\n",
      "China’s Baosteel takes control of Aquila Resources.txt , No found\n",
      "Baosteel__Aquila.txt , No found\n",
      "Kununurra1.txt , No found\n",
      "burleigh_rd1.txt , word = 1\n",
      "JewelProject6.txt , word = 1\n",
      "Breweries_Site1.txt , No found\n",
      "Chiwayland1.txt , word = 1\n",
      "Hoyts.txt , No found\n",
      "Bullabulling4.txt , No found\n",
      "lallal2.txt , No found\n",
      "bullabilling norton.txt , word = 1\n"
     ]
    }
   ],
   "source": [
    "path_possible = 'dataset/2014/possible/'\n",
    "path_relevant = 'dataset/2014/given_relevant/'\n",
    "\n",
    "possible = dict()\n",
    "relevant = dict()\n",
    "\n",
    "for filename in os.listdir(path_possible):\n",
    "    with open(path_possible + filename) as f:\n",
    "        for line in f:\n",
    "            words = line.split()\n",
    "            if words and words[0] == 'HD':\n",
    "                if len(words) == 1:\n",
    "                    print(filename, ', word = 1')\n",
    "                possible[filename] = ' '.join(words[1:])\n",
    "                break\n",
    "        else:\n",
    "            print(filename, ', No found')\n",
    "                \n",
    "for filename in os.listdir(path_relevant):\n",
    "    with open(path_relevant + filename) as f:\n",
    "        for line in f:\n",
    "            words = line.split()\n",
    "            if words and words[0] == 'HD':\n",
    "                if len(words) == 1:\n",
    "                    print(filename, ', word = 1')\n",
    "                relevant[filename] = ' '.join(words[1:])\n",
    "                break\n",
    "        else:\n",
    "            print(filename, ', No found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible['canning markets.txt'] = 'Chinese link to sale of Canning Vale markets'\n",
    "possible['Paladin China nuclear.txt'] = 'Paladin sells mine stake for $US190m'\n",
    "possible['R&F_Melbourne1.txt'] = 'Chinese developers pour cash into apartment sites'\n",
    "possible['puma.txt'] = 'Exclusive: Puma Energy closes hybrid $460m Aussie RCF'\n",
    "possible['China merchants.txt'] = '*China Merchants in Talks to Buy Stake in Four Australia Ports, Source Says'\n",
    "possible['bega milk export.txt'] = 'Bega to supply milk to China in $100m deal'\n",
    "possible['kin mining unnamed chinese investor 3 million.txt'] = 'Kin acquires land on the doorstep of Gwalia mine'\n",
    "\n",
    "relevant['burleigh_rd1.txt'] = \"China's Wanda to Invest $271 Million in Australian Project; Chinese Property Group Has Been on an Overseas Buying Spree\"\n",
    "relevant['bullabilling norton.txt'] = 'Norton to compulsory acquire Bullabulling minorities'\n",
    "relevant['JewelProject6.txt'] = 'Chinese $900m to polish Gold Coast’s Jewel project'\n",
    "relevant['Chiwayland1.txt'] = 'Shanghai developer in $160m apartment venture after listing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = dict()\n",
    "path_txt = 'dataset/2014/txt/'\n",
    "\n",
    "for filename in os.listdir(path_txt):\n",
    "    with open(path_txt + filename) as f:\n",
    "        txt[filename] = f.readline()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norton to compulsory acquire Bullabulling minorities\n",
      "Norton to compulsory acquire Bullabulling minorities\n",
      "{'Viplus1.txt': 'E q u i t y', 'MMG_Glencore_mine.txt': 'b i l l i o n', 'Schild1.txt': 's a l e', 'Margaret_River_Dairy_Company.txt': 'h o m e', 'Nickel_West2.txt': 'W e s t', 'liberty_resources1.txt': 'B E A T', 'Nickel_West3.txt': 'W e s t', 'Hollick1.txt': 's a l e', 'Talison1.txt': 'U S $ 4 7 5 M', 'Poseidon field.txt': 's t a k e', 'Metro_Property_Development.txt': '2 0 1 5', 'Roy_Hill.txt': 'r e n m i n b i', 'Factiva.txt': 's i t e s', 'Wollsthorpe.txt': 'a g r i c u l t u r e', 'canning markets.txt': 'Chinese link to sale of Canning Vale markets', 'Meriton1.txt': 'e m p i r e', 'Golden_cross.txt': 'E Q U I T Y', 'Nickel_West4.txt': 'r u m o r s', 'Paladin China nuclear.txt': 'Paladin sells mine stake for $US190m', 'Saracen.txt': 'b u y', 'Steeple_Hill.txt': 'd e a l', 'Mig33_Foxconn1.txt': 'B R I E F', '570_George_Street1.txt': 'A u s g r i d', 'Meriton2.txt': 's p r e e', 'R&F_Melbourne1.txt': 'Chinese developers pour cash into apartment sites', 'Cauldron1.txt': 'F E R R E T', 'Chinese_Disneyland1.txt': 'c o a s t', 'DTZ.txt': 'b u y', 'Fairfax_house1.txt': 'a g a i n', 'puma.txt': 'Exclusive: Puma Energy closes hybrid $460m Aussie RCF', 'Port_Spencer1.txt': 'P o r t', 'Montagu_Dairy.txt': 'C h i n e s e', '97_Franklin_Street.txt': 'g o l d', 'Envestra.txt': 'a c q u i s i t i o n s', 'RIFA1.txt': 'E X C L U S I V E', 'Banco group southbank site-DESKTOP-D85LL46.txt': 'G a i n', 'Iron_Ore_Holdings.txt': 'l i e u t e n a n t', 'Banco group southbank site.txt': 'G a i n', 'QueensWharf1.txt': '\\xad', 'FAILED.txt': 'a c q u i s i t i o n s', 'Metro_Property_Development-DESKTOP-D85LL46.txt': '2 0 1 5', 'GoldenHorse1.txt': '$ 3 5 0 m', 'Patricks1.txt': 's l o w', 'China merchants.txt': '*China Merchants in Talks to Buy Stake in Four Australia Ports, Source Says', 'QBE_sydney1.txt': 'm a r k e t s', 'GoldenHorse2.txt': 'b r i e f s', 'COFCO_Noble.txt': 'W A', 'GoldenHorse3.txt': 'p i p e l i n e', 'Argyle_Smoke_Creek.txt': 'm i n e', 'Lionhub.txt': 'p a r k', 'Agenix_HepB.txt': 'F E R R E T', 'Gold coast cruise ship terminal2.txt': 'u p', 'Curtis_Island1-DESKTOP-D85LL46.txt': 'a s s e t s', 'LinksHope3.txt': 'u p', 'Sovereign_Gold.txt': 'G r o u p', 'Tuileries1.txt': 'b o o n', 'Nickel_West.txt': 'b l e s s i n g', 'Aspire.txt': 'A s p i r e', 'bega milk export.txt': 'Bega to supply milk to China in $100m deal', 'kin mining unnamed chinese investor 3 million.txt': 'Kin acquires land on the doorstep of Gwalia mine', 'UDP1.txt': 'm i l k', 'Envestra1.txt': 'a c q u i s i t i o n s', 'Yorkeys_Knob.txt': 'l a n d', 'Cairns_Casino1.txt': 'b e a c h e s', 'Gold coast cruise ship terminal.txt': 'c a r d s', 'Balamara1.txt': 'P r o j e c t', 'Meekathara.txt': 'H B J', 'Snow_Dragon.txt': 's t a t i o n s', 'Brisbane_casino_Greenland.txt': 'p e r m i t s', 'Minjah.txt': 'E X C L U S I V E', 'MMG_Glencore_mine-DESKTOP-D85LL46.txt': 'b i l l i o n', 'VDL1.txt': 'c a s h', 'UDP2.txt': 'E X C L U S I V E', 'Envestra2.txt': 'b i d', '66a_Doncaster_Avenue1.txt': 'R a n d w i c k', '617_Pacific_Highway.txt': 's i t e', 'Rymill1.txt': 's a l e', 'Balamara2.txt': 'm i l l i o n . . .', '50_Dunning_Avenue_Sydney.txt': 'd e m a n d', 'The_Drip1.txt': 'p i t t a n c e', 'Envestra3.txt': 'A P A', 'UDP3.txt': 'c h u r n s', 'DTZ2.txt': 'D T Z', 'southport_central1.txt': 'b a r g a i n', 'Chateau_Yaldara1.txt': '2 0 1 4', 'Envestra6.txt': 'B R I E F', 'airlie_beach.txt': 'B e a c h', 'UDP6.txt': 'i n v e s t o r', 'UDP4.txt': 'w o r t h', 'Carmichael_coal_mine.txt': 'p r o j e c t', 'Envestra4.txt': 't o', 'Curtis_Island1.txt': 'a s s e t s', 'Lionhub2.txt': 'v e n t u r e', 'Chateau_Yaldara2.txt': 'v a l u e s', 'Port_of_Melbourne.txt': 'u p', 'hoyts1.txt': 'e s t a t e', 'Macquarie_Generation.txt': 'D e l t a', 'Envestra5.txt': 's n a g', 'NQBE.txt': 'C O N T I N U E', 'Karinga_creek1.txt': 'r e s o u r c e', 'UDP5.txt': 'R o u n d u p', 'FAILED2.txt': 'A d v e n t u r e'}\n"
     ]
    }
   ],
   "source": [
    "print(txt['Factiva-20180828-2340_部分30.txt'])\n",
    "print(relevant['bullabilling norton.txt'])\n",
    "txt['Factiva-20180828-2340_部分30.txt'] == relevant['bullabilling norton.txt']\n",
    "print(possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "r_path = './dataset/2014/relevant/'\n",
    "u_path = './dataset/2014/unrelevant/'\n",
    "num = 0\n",
    "num2 = 0\n",
    "title = set()\n",
    "for k, v in txt.items():\n",
    "    if v in relevant.values():\n",
    "        num += 1\n",
    "        if v in title:\n",
    "            break\n",
    "            title.add(v)\n",
    "        shutil.copyfile(path_txt + k, r_path + str(num) + '.txt')\n",
    "for k, v in txt.items():\n",
    "    if v in possible.values():\n",
    "        num += 1\n",
    "        if v in title:\n",
    "            break\n",
    "        title.add(v)\n",
    "        shutil.copyfile(path_txt + k, r_path + str(num) + '.txt')\n",
    "for k, v in txt.items():\n",
    "    if v not in title:\n",
    "        num += 1\n",
    "        shutil.copyfile(path_txt + k, u_path + str(num) + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 122\n",
      "102 114\n",
      "219\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('dataset/2014/possible/')), len(os.listdir('dataset/2014/given_relevant/')))\n",
    "print(len(possible), len(relevant))\n",
    "print(len(os.listdir('dataset/2014/relevant/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in possible.items():\n",
    "    if k in relevant:\n",
    "        print(k)\n",
    "print()     \n",
    "for k,v in relevant.items():\n",
    "    if k in possible:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation\n",
    "\n",
    "## Done\n",
    "- Dataset\n",
    "    - Download all articles in 2014\n",
    "    - it's very hard to label them (e.g same title)\n",
    "    - label 90% \n",
    "- Data cleaning\n",
    "    - remove same file\n",
    "    - remove useless content\n",
    "- ML\n",
    "    - fasttext/LogisticRegression/SVC/NB/KNC\n",
    "    - great performance\n",
    "    \n",
    "## Future work\n",
    "- Dataset\n",
    "    - label issue: similarity of document, manual work\n",
    "    - extract field (e.g title/word count/location/language)\n",
    "    - continued: data cleaning (e.g webpage)\n",
    "- System integration\n",
    "    - environment\n",
    "    - database\n",
    "- Model\n",
    "    - better visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
