{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preproccess functionï¼štext -> token and word vector\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stopwords_en = set(stopwords.words('english'))\n",
    "\n",
    "__tokenization_pattern = r'''(?x)          # set flag to allow verbose regexps\n",
    "        \\$?\\d+(?:\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "      | (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "      | \\w+(?:-\\w+)*        # words with optional internal hyphens\n",
    "      | \\.\\.\\.              # ellipsis\n",
    "      | [][.,;\"'?():_`-]    # these are separate tokens; includes ], [\n",
    "    '''\n",
    "tokenizer = nltk.tokenize.regexp.RegexpTokenizer(__tokenization_pattern)\n",
    "\n",
    "def preprocessor(text):\n",
    "    stems = []\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    for token in tokens:\n",
    "        if token.isalpha() and token not in stopwords_en:\n",
    "            stems.append(str(stemmer.stem(token)))\n",
    "    return stems\n",
    "\n",
    "bow_vectorizer = CountVectorizer(lowercase = False, \n",
    "                                 tokenizer = lambda x: x, # because we already have tokens available\n",
    "                                 stop_words = None, ## stop words removal already done from NLTK\n",
    "                                 max_features = 5000, ## pick top 5K words by frequency\n",
    "                                 ngram_range = (1, 1), ## we want unigrams now\n",
    "                                 binary = False) ## we want as binary/boolean features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text from files and proccess them to word vector\n",
    "path_base = 'dataset/'\n",
    "path_years = ['2014/', '2015/', '2016/']\n",
    "path_category = 'category'\n",
    "\n",
    "token = list()\n",
    "x = list()\n",
    "y = list()\n",
    "c1 = 0\n",
    "c2 = 0\n",
    "\n",
    "for year in path_years:\n",
    "    for category in ['1', '2']:\n",
    "        path = path_base + year + path_category + category +'/'\n",
    "        for filename in os.listdir(path):\n",
    "            with open (path + filename, \"r\") as f:\n",
    "                text = f.read().replace(u'\\xa0', ' ').replace('\\n', ' ')\n",
    "                token.append(preprocessor(text))\n",
    "                y.append(category)\n",
    "                if category == '1':\n",
    "                    c1 += 1\n",
    "                else:\n",
    "                    c2 += 1\n",
    "text_vec = bow_vectorizer.fit_transform(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 documents\n",
      "category1: 472 \n",
      "category2: 419\n"
     ]
    }
   ],
   "source": [
    "print(len(y), 'documents')\n",
    "print('category1:', c1, '\\ncategory2:', c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for 50 times:\n",
      "\n",
      "1 time\n",
      "accuracy 0.652173913043\n",
      "  prec  rec   F1\n",
      "0 0.64 0.64 0.64\n",
      "1 0.66 0.66 0.66\n",
      "2 time\n",
      "accuracy 0.619834710744\n",
      "  prec  rec   F1\n",
      "0 0.63 0.61 0.62\n",
      "1 0.61 0.63 0.62\n",
      "3 time\n",
      "accuracy 0.666666666667\n",
      "  prec  rec   F1\n",
      "0 0.70 0.63 0.66\n",
      "1 0.63 0.71 0.67\n",
      "4 time\n",
      "accuracy 0.658227848101\n",
      "  prec  rec   F1\n",
      "0 0.73 0.65 0.68\n",
      "1 0.59 0.67 0.63\n",
      "5 time\n",
      "accuracy 0.64\n",
      "  prec  rec   F1\n",
      "0 0.68 0.66 0.67\n",
      "1 0.59 0.62 0.60\n",
      "6 time\n",
      "accuracy 0.649289099526\n",
      "  prec  rec   F1\n",
      "0 0.60 0.76 0.67\n",
      "1 0.72 0.55 0.63\n",
      "7 time\n",
      "accuracy 0.679069767442\n",
      "  prec  rec   F1\n",
      "0 0.71 0.69 0.70\n",
      "1 0.64 0.66 0.65\n",
      "8 time\n",
      "accuracy 0.651452282158\n",
      "  prec  rec   F1\n",
      "0 0.69 0.60 0.64\n",
      "1 0.62 0.71 0.66\n",
      "9 time\n",
      "accuracy 0.672811059908\n",
      "  prec  rec   F1\n",
      "0 0.77 0.55 0.64\n",
      "1 0.61 0.81 0.70\n",
      "10 time\n",
      "accuracy 0.695652173913\n",
      "  prec  rec   F1\n",
      "0 0.77 0.66 0.71\n",
      "1 0.62 0.74 0.68\n",
      "11 time\n",
      "accuracy 0.617224880383\n",
      "  prec  rec   F1\n",
      "0 0.71 0.50 0.58\n",
      "1 0.56 0.76 0.65\n",
      "12 time\n",
      "accuracy 0.66511627907\n",
      "  prec  rec   F1\n",
      "0 0.78 0.60 0.68\n",
      "1 0.57 0.76 0.65\n",
      "13 time\n",
      "accuracy 0.648888888889\n",
      "  prec  rec   F1\n",
      "0 0.68 0.59 0.63\n",
      "1 0.63 0.71 0.67\n",
      "14 time\n",
      "accuracy 0.623966942149\n",
      "  prec  rec   F1\n",
      "0 0.67 0.62 0.65\n",
      "1 0.57 0.63 0.60\n",
      "15 time\n",
      "accuracy 0.642156862745\n",
      "  prec  rec   F1\n",
      "0 0.63 0.76 0.69\n",
      "1 0.67 0.51 0.58\n",
      "16 time\n",
      "accuracy 0.591928251121\n",
      "  prec  rec   F1\n",
      "0 0.64 0.65 0.64\n",
      "1 0.53 0.52 0.52\n",
      "17 time\n",
      "accuracy 0.625\n",
      "  prec  rec   F1\n",
      "0 0.62 0.59 0.60\n",
      "1 0.63 0.66 0.65\n",
      "18 time\n",
      "accuracy 0.70297029703\n",
      "  prec  rec   F1\n",
      "0 0.73 0.72 0.73\n",
      "1 0.67 0.68 0.67\n",
      "19 time\n",
      "accuracy 0.667984189723\n",
      "  prec  rec   F1\n",
      "0 0.74 0.56 0.64\n",
      "1 0.62 0.79 0.69\n",
      "20 time\n",
      "accuracy 0.679069767442\n",
      "  prec  rec   F1\n",
      "0 0.70 0.63 0.66\n",
      "1 0.66 0.73 0.69\n",
      "21 time\n",
      "accuracy 0.627802690583\n",
      "  prec  rec   F1\n",
      "0 0.65 0.62 0.63\n",
      "1 0.60 0.64 0.62\n",
      "22 time\n",
      "accuracy 0.668224299065\n",
      "  prec  rec   F1\n",
      "0 0.78 0.57 0.66\n",
      "1 0.59 0.79 0.68\n",
      "23 time\n",
      "accuracy 0.627118644068\n",
      "  prec  rec   F1\n",
      "0 0.66 0.66 0.66\n",
      "1 0.58 0.58 0.58\n",
      "24 time\n",
      "accuracy 0.659090909091\n",
      "  prec  rec   F1\n",
      "0 0.67 0.65 0.66\n",
      "1 0.65 0.66 0.65\n",
      "25 time\n",
      "accuracy 0.728110599078\n",
      "  prec  rec   F1\n",
      "0 0.81 0.67 0.73\n",
      "1 0.66 0.80 0.73\n",
      "26 time\n",
      "accuracy 0.646226415094\n",
      "  prec  rec   F1\n",
      "0 0.72 0.62 0.66\n",
      "1 0.58 0.68 0.63\n",
      "27 time\n",
      "accuracy 0.648305084746\n",
      "  prec  rec   F1\n",
      "0 0.71 0.54 0.61\n",
      "1 0.61 0.76 0.68\n",
      "28 time\n",
      "accuracy 0.64224137931\n",
      "  prec  rec   F1\n",
      "0 0.73 0.54 0.62\n",
      "1 0.59 0.77 0.66\n",
      "29 time\n",
      "accuracy 0.606481481481\n",
      "  prec  rec   F1\n",
      "0 0.65 0.56 0.60\n",
      "1 0.57 0.66 0.61\n",
      "30 time\n",
      "accuracy 0.64\n",
      "  prec  rec   F1\n",
      "0 0.67 0.60 0.63\n",
      "1 0.61 0.68 0.65\n",
      "31 time\n",
      "accuracy 0.674528301887\n",
      "  prec  rec   F1\n",
      "0 0.70 0.59 0.64\n",
      "1 0.66 0.76 0.70\n",
      "32 time\n",
      "accuracy 0.636363636364\n",
      "  prec  rec   F1\n",
      "0 0.68 0.61 0.64\n",
      "1 0.60 0.67 0.63\n",
      "33 time\n",
      "accuracy 0.600896860987\n",
      "  prec  rec   F1\n",
      "0 0.61 0.58 0.59\n",
      "1 0.59 0.62 0.61\n",
      "34 time\n",
      "accuracy 0.676855895197\n",
      "  prec  rec   F1\n",
      "0 0.71 0.64 0.67\n",
      "1 0.65 0.72 0.68\n",
      "35 time\n",
      "accuracy 0.653333333333\n",
      "  prec  rec   F1\n",
      "0 0.69 0.60 0.64\n",
      "1 0.62 0.71 0.66\n",
      "36 time\n",
      "accuracy 0.675925925926\n",
      "  prec  rec   F1\n",
      "0 0.72 0.67 0.69\n",
      "1 0.64 0.69 0.66\n",
      "37 time\n",
      "accuracy 0.637254901961\n",
      "  prec  rec   F1\n",
      "0 0.68 0.69 0.68\n",
      "1 0.58 0.57 0.57\n",
      "38 time\n",
      "accuracy 0.66511627907\n",
      "  prec  rec   F1\n",
      "0 0.78 0.52 0.62\n",
      "1 0.60 0.83 0.70\n",
      "39 time\n",
      "accuracy 0.650862068966\n",
      "  prec  rec   F1\n",
      "0 0.69 0.59 0.63\n",
      "1 0.62 0.72 0.67\n",
      "40 time\n",
      "accuracy 0.626666666667\n",
      "  prec  rec   F1\n",
      "0 0.66 0.64 0.65\n",
      "1 0.58 0.61 0.60\n",
      "41 time\n",
      "accuracy 0.657534246575\n",
      "  prec  rec   F1\n",
      "0 0.73 0.57 0.64\n",
      "1 0.61 0.76 0.68\n",
      "42 time\n",
      "accuracy 0.66814159292\n",
      "  prec  rec   F1\n",
      "0 0.72 0.63 0.67\n",
      "1 0.62 0.71 0.66\n",
      "43 time\n",
      "accuracy 0.709090909091\n",
      "  prec  rec   F1\n",
      "0 0.75 0.71 0.73\n",
      "1 0.66 0.70 0.68\n",
      "44 time\n",
      "accuracy 0.608490566038\n",
      "  prec  rec   F1\n",
      "0 0.66 0.58 0.62\n",
      "1 0.56 0.64 0.60\n",
      "45 time\n",
      "accuracy 0.677685950413\n",
      "  prec  rec   F1\n",
      "0 0.73 0.64 0.68\n",
      "1 0.63 0.72 0.67\n",
      "46 time\n",
      "accuracy 0.608040201005\n",
      "  prec  rec   F1\n",
      "0 0.68 0.50 0.58\n",
      "1 0.56 0.73 0.63\n",
      "47 time\n",
      "accuracy 0.647058823529\n",
      "  prec  rec   F1\n",
      "0 0.64 0.64 0.64\n",
      "1 0.65 0.65 0.65\n",
      "48 time\n",
      "accuracy 0.585774058577\n",
      "  prec  rec   F1\n",
      "0 0.61 0.53 0.57\n",
      "1 0.56 0.65 0.60\n",
      "49 time\n",
      "accuracy 0.637931034483\n",
      "  prec  rec   F1\n",
      "0 0.71 0.49 0.58\n",
      "1 0.60 0.79 0.68\n",
      "50 time\n",
      "accuracy 0.642487046632\n",
      "  prec  rec   F1\n",
      "0 0.67 0.70 0.69\n",
      "1 0.60 0.56 0.58\n",
      "\n",
      "\n",
      "\n",
      "average accuracy = 0.6496624736438014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "sum = 0\n",
    "print(\"accuracy for 50 times:\\n\")\n",
    "for i in range(50):\n",
    "    # Split the dataset to train set and test set\n",
    "    msk = np.random.rand(len(y)) < 0.75\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "\n",
    "    train_x = text_vec[msk]\n",
    "    test_x = text_vec[~msk]\n",
    "\n",
    "    y = le.fit_transform(y)\n",
    "    train_y = y[msk]\n",
    "    test_y = y[~msk]\n",
    "    \n",
    "    # Train with MultinomialNB\n",
    "    \n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(train_x, train_y)\n",
    "    \n",
    "    # Get prediction\n",
    "    preds_bow = classifier.predict(test_x)\n",
    "    to_print = [le.inverse_transform(pred) for pred in preds_bow ]\n",
    "    # print(to_print)\n",
    "    \n",
    "    \n",
    "    # Calculate accuracy\n",
    "    confusion = confusion_matrix(test_y, preds_bow)\n",
    "    acc_bow = accuracy_score(test_y, preds_bow)\n",
    "    precisions_bow, recalls_bow, f1_scores_bow, _ = precision_recall_fscore_support(test_y, preds_bow)\n",
    "    sum += acc_bow\n",
    "    print(i+1, 'time')\n",
    "    print('accuracy', acc_bow)\n",
    "    print(\"{:>1} {:>4} {:>4} {:>4}\".format(\"\", \"prec\", \"rec\", \"F1\"))\n",
    "    for (idx, scores) in enumerate(zip(precisions_bow, recalls_bow, f1_scores_bow)):\n",
    "        print(\"{:>1} {:.2f} {:.2f} {:.2f}\".format(\n",
    "            le.inverse_transform(idx), scores[0], scores[1], scores[2]\n",
    "        ))\n",
    "    print()\n",
    "#     print('confusion matrix:\\n{}'.format( confusion) )\n",
    "    \n",
    "print(\"\\n\\n\\naverage accuracy = {}\".format(sum / 50))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
