{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preproccess functionï¼štext -> token and word vector\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stopwords_en = set(stopwords.words('english'))\n",
    "\n",
    "__tokenization_pattern = r'''(?x)          # set flag to allow verbose regexps\n",
    "        \\$?\\d+(?:\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "      | (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "      | \\w+(?:-\\w+)*        # words with optional internal hyphens\n",
    "      | \\.\\.\\.              # ellipsis\n",
    "      | [][.,;\"'?():_`-]    # these are separate tokens; includes ], [\n",
    "    '''\n",
    "tokenizer = nltk.tokenize.regexp.RegexpTokenizer(__tokenization_pattern)\n",
    "\n",
    "def preprocessor(text):\n",
    "    stems = []\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    for token in tokens:\n",
    "        if token.isalpha() and token not in stopwords_en:\n",
    "            stems.append(str(stemmer.stem(token)))\n",
    "    return stems\n",
    "\n",
    "bow_vectorizer = CountVectorizer(lowercase = False, \n",
    "                                 tokenizer = lambda x: x, # because we already have tokens available\n",
    "                                 stop_words = None, ## stop words removal already done from NLTK\n",
    "                                 max_features = 5000, ## pick top 5K words by frequency\n",
    "                                 ngram_range = (1, 1), ## we want unigrams now\n",
    "                                 binary = False) ## we want as binary/boolean features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text from files and proccess them to word vector\n",
    "path_base = 'dataset/'\n",
    "path_years = ['2014/', '2015/', '2016/']\n",
    "path_category = 'category'\n",
    "\n",
    "token = list()\n",
    "x = list()\n",
    "y = list()\n",
    "c1 = 0\n",
    "c2 = 0\n",
    "\n",
    "for year in path_years:\n",
    "    for category in ['1', '2']:\n",
    "        path = path_base + year + path_category + category +'/'\n",
    "        for filename in os.listdir(path):\n",
    "            with open (path + filename, \"r\") as f:\n",
    "                text = f.read().replace(u'\\xa0', ' ').replace('\\n', ' ')\n",
    "                token.append(preprocessor(text))\n",
    "                y.append(category)\n",
    "                if category == '1':\n",
    "                    c1 += 1\n",
    "                else:\n",
    "                    c2 += 1\n",
    "text_vec = bow_vectorizer.fit_transform(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 documents\n",
      "category1: 472 \n",
      "category2: 419\n"
     ]
    }
   ],
   "source": [
    "print(len(y), 'documents')\n",
    "print('category1:', c1, '\\ncategory2:', c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for 50 times:\n",
      "\n",
      "1 time\n",
      "accuracy 0.646766169154\n",
      "  prec  rec   F1\n",
      "0 0.77 0.51 0.61\n",
      "1 0.58 0.81 0.68\n",
      "\n",
      "2 time\n",
      "accuracy 0.627192982456\n",
      "  prec  rec   F1\n",
      "0 0.70 0.54 0.61\n",
      "1 0.58 0.72 0.64\n",
      "\n",
      "3 time\n",
      "accuracy 0.654166666667\n",
      "  prec  rec   F1\n",
      "0 0.61 0.68 0.65\n",
      "1 0.70 0.63 0.66\n",
      "\n",
      "4 time\n",
      "accuracy 0.64\n",
      "  prec  rec   F1\n",
      "0 0.73 0.58 0.65\n",
      "1 0.57 0.71 0.63\n",
      "\n",
      "5 time\n",
      "accuracy 0.617924528302\n",
      "  prec  rec   F1\n",
      "0 0.74 0.48 0.58\n",
      "1 0.55 0.79 0.65\n",
      "\n",
      "6 time\n",
      "accuracy 0.636752136752\n",
      "  prec  rec   F1\n",
      "0 0.65 0.63 0.64\n",
      "1 0.62 0.64 0.63\n",
      "\n",
      "7 time\n",
      "accuracy 0.623430962343\n",
      "  prec  rec   F1\n",
      "0 0.69 0.57 0.62\n",
      "1 0.57 0.69 0.62\n",
      "\n",
      "8 time\n",
      "accuracy 0.657894736842\n",
      "  prec  rec   F1\n",
      "0 0.67 0.61 0.64\n",
      "1 0.65 0.70 0.68\n",
      "\n",
      "9 time\n",
      "accuracy 0.668103448276\n",
      "  prec  rec   F1\n",
      "0 0.72 0.60 0.65\n",
      "1 0.63 0.75 0.68\n",
      "\n",
      "10 time\n",
      "accuracy 0.651260504202\n",
      "  prec  rec   F1\n",
      "0 0.72 0.54 0.62\n",
      "1 0.61 0.77 0.68\n",
      "\n",
      "11 time\n",
      "accuracy 0.593073593074\n",
      "  prec  rec   F1\n",
      "0 0.59 0.68 0.63\n",
      "1 0.60 0.50 0.54\n",
      "\n",
      "12 time\n",
      "accuracy 0.635964912281\n",
      "  prec  rec   F1\n",
      "0 0.69 0.59 0.63\n",
      "1 0.59 0.69 0.64\n",
      "\n",
      "13 time\n",
      "accuracy 0.633484162896\n",
      "  prec  rec   F1\n",
      "0 0.65 0.68 0.67\n",
      "1 0.61 0.58 0.59\n",
      "\n",
      "14 time\n",
      "accuracy 0.647321428571\n",
      "  prec  rec   F1\n",
      "0 0.66 0.61 0.64\n",
      "1 0.63 0.68 0.66\n",
      "\n",
      "15 time\n",
      "accuracy 0.67\n",
      "  prec  rec   F1\n",
      "0 0.74 0.65 0.69\n",
      "1 0.60 0.70 0.65\n",
      "\n",
      "16 time\n",
      "accuracy 0.642857142857\n",
      "  prec  rec   F1\n",
      "0 0.62 0.62 0.62\n",
      "1 0.67 0.66 0.66\n",
      "\n",
      "17 time\n",
      "accuracy 0.660792951542\n",
      "  prec  rec   F1\n",
      "0 0.71 0.67 0.69\n",
      "1 0.61 0.65 0.63\n",
      "\n",
      "18 time\n",
      "accuracy 0.599118942731\n",
      "  prec  rec   F1\n",
      "0 0.62 0.52 0.57\n",
      "1 0.58 0.68 0.63\n",
      "\n",
      "19 time\n",
      "accuracy 0.561181434599\n",
      "  prec  rec   F1\n",
      "0 0.60 0.47 0.53\n",
      "1 0.54 0.66 0.59\n",
      "\n",
      "20 time\n",
      "accuracy 0.665137614679\n",
      "  prec  rec   F1\n",
      "0 0.79 0.51 0.62\n",
      "1 0.60 0.84 0.70\n",
      "\n",
      "21 time\n",
      "accuracy 0.63025210084\n",
      "  prec  rec   F1\n",
      "0 0.67 0.56 0.61\n",
      "1 0.60 0.70 0.65\n",
      "\n",
      "22 time\n",
      "accuracy 0.634042553191\n",
      "  prec  rec   F1\n",
      "0 0.67 0.57 0.62\n",
      "1 0.60 0.70 0.65\n",
      "\n",
      "23 time\n",
      "accuracy 0.671361502347\n",
      "  prec  rec   F1\n",
      "0 0.78 0.57 0.66\n",
      "1 0.60 0.80 0.68\n",
      "\n",
      "24 time\n",
      "accuracy 0.619047619048\n",
      "  prec  rec   F1\n",
      "0 0.72 0.64 0.68\n",
      "1 0.49 0.58 0.53\n",
      "\n",
      "25 time\n",
      "accuracy 0.668292682927\n",
      "  prec  rec   F1\n",
      "0 0.74 0.59 0.66\n",
      "1 0.61 0.76 0.68\n",
      "\n",
      "26 time\n",
      "accuracy 0.671232876712\n",
      "  prec  rec   F1\n",
      "0 0.72 0.58 0.64\n",
      "1 0.64 0.77 0.70\n",
      "\n",
      "27 time\n",
      "accuracy 0.616915422886\n",
      "  prec  rec   F1\n",
      "0 0.75 0.51 0.61\n",
      "1 0.53 0.76 0.63\n",
      "\n",
      "28 time\n",
      "accuracy 0.629807692308\n",
      "  prec  rec   F1\n",
      "0 0.69 0.53 0.60\n",
      "1 0.59 0.74 0.66\n",
      "\n",
      "29 time\n",
      "accuracy 0.646226415094\n",
      "  prec  rec   F1\n",
      "0 0.73 0.64 0.68\n",
      "1 0.55 0.65 0.60\n",
      "\n",
      "30 time\n",
      "accuracy 0.654008438819\n",
      "  prec  rec   F1\n",
      "0 0.65 0.69 0.67\n",
      "1 0.66 0.61 0.63\n",
      "\n",
      "31 time\n",
      "accuracy 0.637860082305\n",
      "  prec  rec   F1\n",
      "0 0.71 0.55 0.62\n",
      "1 0.59 0.74 0.66\n",
      "\n",
      "32 time\n",
      "accuracy 0.666666666667\n",
      "  prec  rec   F1\n",
      "0 0.78 0.57 0.66\n",
      "1 0.59 0.80 0.68\n",
      "\n",
      "33 time\n",
      "accuracy 0.635555555556\n",
      "  prec  rec   F1\n",
      "0 0.67 0.59 0.63\n",
      "1 0.60 0.68 0.64\n",
      "\n",
      "34 time\n",
      "accuracy 0.661224489796\n",
      "  prec  rec   F1\n",
      "0 0.66 0.70 0.68\n",
      "1 0.66 0.62 0.64\n",
      "\n",
      "35 time\n",
      "accuracy 0.657258064516\n",
      "  prec  rec   F1\n",
      "0 0.67 0.66 0.66\n",
      "1 0.64 0.66 0.65\n",
      "\n",
      "36 time\n",
      "accuracy 0.633928571429\n",
      "  prec  rec   F1\n",
      "0 0.72 0.56 0.63\n",
      "1 0.57 0.73 0.64\n",
      "\n",
      "37 time\n",
      "accuracy 0.658767772512\n",
      "  prec  rec   F1\n",
      "0 0.67 0.63 0.65\n",
      "1 0.65 0.69 0.67\n",
      "\n",
      "38 time\n",
      "accuracy 0.684931506849\n",
      "  prec  rec   F1\n",
      "0 0.73 0.61 0.67\n",
      "1 0.65 0.76 0.70\n",
      "\n",
      "39 time\n",
      "accuracy 0.626794258373\n",
      "  prec  rec   F1\n",
      "0 0.68 0.53 0.60\n",
      "1 0.59 0.73 0.65\n",
      "\n",
      "40 time\n",
      "accuracy 0.636363636364\n",
      "  prec  rec   F1\n",
      "0 0.66 0.60 0.63\n",
      "1 0.62 0.67 0.64\n",
      "\n",
      "41 time\n",
      "accuracy 0.676056338028\n",
      "  prec  rec   F1\n",
      "0 0.73 0.57 0.64\n",
      "1 0.64 0.78 0.70\n",
      "\n",
      "42 time\n",
      "accuracy 0.66028708134\n",
      "  prec  rec   F1\n",
      "0 0.74 0.53 0.62\n",
      "1 0.61 0.80 0.70\n",
      "\n",
      "43 time\n",
      "accuracy 0.613526570048\n",
      "  prec  rec   F1\n",
      "0 0.66 0.57 0.61\n",
      "1 0.57 0.67 0.62\n",
      "\n",
      "44 time\n",
      "accuracy 0.622317596567\n",
      "  prec  rec   F1\n",
      "0 0.73 0.48 0.58\n",
      "1 0.56 0.79 0.66\n",
      "\n",
      "45 time\n",
      "accuracy 0.65690376569\n",
      "  prec  rec   F1\n",
      "0 0.70 0.60 0.65\n",
      "1 0.62 0.72 0.67\n",
      "\n",
      "46 time\n",
      "accuracy 0.636771300448\n",
      "  prec  rec   F1\n",
      "0 0.75 0.50 0.60\n",
      "1 0.57 0.80 0.67\n",
      "\n",
      "47 time\n",
      "accuracy 0.646226415094\n",
      "  prec  rec   F1\n",
      "0 0.76 0.50 0.60\n",
      "1 0.58 0.82 0.68\n",
      "\n",
      "48 time\n",
      "accuracy 0.658878504673\n",
      "  prec  rec   F1\n",
      "0 0.70 0.61 0.65\n",
      "1 0.62 0.72 0.67\n",
      "\n",
      "49 time\n",
      "accuracy 0.692307692308\n",
      "  prec  rec   F1\n",
      "0 0.75 0.62 0.68\n",
      "1 0.65 0.77 0.71\n",
      "\n",
      "50 time\n",
      "accuracy 0.574074074074\n",
      "  prec  rec   F1\n",
      "0 0.70 0.50 0.58\n",
      "1 0.48 0.69 0.57\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "average accuracy = 0.6422062313006375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "sum = 0\n",
    "print(\"accuracy for 50 times:\\n\")\n",
    "for i in range(50):\n",
    "    # Split the dataset to train set and test set\n",
    "    msk = np.random.rand(len(y)) < 0.75\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "\n",
    "    train_x = text_vec[msk]\n",
    "    test_x = text_vec[~msk]\n",
    "\n",
    "    y = le.fit_transform(y)\n",
    "    train_y = y[msk]\n",
    "    test_y = y[~msk]\n",
    "    \n",
    "    # Train with MultinomialNB\n",
    "    \n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(train_x, train_y)\n",
    "    \n",
    "    # Get prediction\n",
    "    preds_bow = classifier.predict(test_x)\n",
    "    to_print = [le.inverse_transform(pred) for pred in preds_bow ]\n",
    "    # print(to_print)\n",
    "    \n",
    "    \n",
    "    # Calculate accuracy\n",
    "    confusion = confusion_matrix(test_y, preds_bow)\n",
    "    acc_bow = accuracy_score(test_y, preds_bow)\n",
    "    precisions_bow, recalls_bow, f1_scores_bow, _ = precision_recall_fscore_support(test_y, preds_bow)\n",
    "    sum += acc_bow\n",
    "    print(i+1, 'time')\n",
    "    print('accuracy', acc_bow)\n",
    "    print(\"{:>1} {:>4} {:>4} {:>4}\".format(\"\", \"prec\", \"rec\", \"F1\"))\n",
    "    for (idx, scores) in enumerate(zip(precisions_bow, recalls_bow, f1_scores_bow)):\n",
    "        print(\"{:>1} {:.2f} {:.2f} {:.2f}\".format(\n",
    "            le.inverse_transform(idx), scores[0], scores[1], scores[2]\n",
    "        ))\n",
    "    print()\n",
    "#     print('confusion matrix:\\n{}'.format( confusion) )\n",
    "    \n",
    "print(\"\\n\\n\\naverage accuracy = {}\".format(sum / 50))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
